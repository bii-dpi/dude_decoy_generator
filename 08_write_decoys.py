"""Write decoys from qualifying candidates to disk for the referenced job."""

import os
import pickle
import argparse
import numpy as np
import pandas as pd
from progressbar import progressbar
from collections import Counter, defaultdict


print("Selecting and writing decoys for each active...")

np.random.seed(12345)

ZINC_SMILES = np.load("data/all_zinc_smiles_ref.npy",
                      allow_pickle=True).flatten()


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Supply job name and output path.")
    parser.add_argument("job_name",
                        help="Job name to be used to load the decoy candidates.")
    parser.add_argument("-o", default=None,
                        help="Decoy file output path. Default: data/{job_name}_decoys")
    args = vars(parser.parse_args())

    output_path = args["o"]
    if not output_path:
        output_path = f"data/{job_name}_decoys"
        print(f"No output path supplied; writing decoys to {output_path}")

    print(f"[1/3] Loading decoy candidate dictionary...")
    candidate_dict = \
        {smiles_pair: ZINC_SMILES[indices.astype(int)].tolist()
         for smiles_pair, indices in
         pd.read_pickle(f"data/candidate_dicts/{args['job_name']}.pkl").items()
         if len(indices)}

    # Load qualifying candidates, as generated by 07, to filter candidate_dict.
    with open(f"data/cache/{args['job_name']}/qualifying_candidates", "r") as f:
        qualifying_candidates = [smiles.strip("\n") for smiles in f.readlines()]
    # Create a hash table for quick look-up.
    qualifying_candidates = dict(zip(qualifying_candidates,
                                     [[] for _ in qualifying_candidates]))

    for smiles_pair in progressbar(candidate_dict):
        candidate_dict[smiles_pair] = \
            [curr_smiles for curr_smiles in candidate_dict[smiles_pair]
             if curr_smiles in qualifying_candidates]

    # Remove any SMILES pairs without any candidates left after filtration.
    candidate_dict = {smiles_pair: candidate_smiles
                      for smiles_pair, candidate_smiles in candidate_dict.items()
                      if len(candidate_smiles)}

    print(f"[2/3] Setting candidate priority by its duplicatedness...")
    # Calculate candidate counts.
    all_qualified = [smiles for candidate_smiles in candidate_dict.values()
                     for smiles in candidate_smiles]
    candidate_counts = Counter(all_qualified)
    sorting_key = lambda smiles: candidate_counts[smiles]

    for smiles_pair, candidate_smiles in progressbar(candidate_dict.items()):
        candidate_dict[smiles_pair] = sorted(candidate_smiles, key=sorting_key)

    actives_dict = defaultdict(set)
    failed_actives = []
    for smiles_pair, candidate_smiles in progressbar(candidate_dict.items()):
        actives_dict[smiles_pair.split("_")[0]].update(candidate_smiles)

    for active_smiles, candidate_smiles in progressbar(actives_dict.items()):
        if len(candidate_smiles) < 50:
            failed_actives.append(active_smiles)
        else:
            actives_dict[active_smiles] = \
                sorted(list(candidate_smiles), key=sorting_key)[:50]

    actives_dict = {active_smiles: candidate_smiles
                    for active_smiles, candidate_smiles in actives_dict.items()
                    if len(candidate_smiles) >= 50}

    print(len(failed_actives), "failed")
    # Need to save these elsewhere and say that I am, and where.

    print(f"[4/4] Writing decoys...")
    to_write = []
    for active_smiles, decoy_list in actives_dict.items():
        for decoy_smiles in decoy_list:
            to_write.append(f"{active_smiles} {decoy_smiles}")

    with open(output_path, "w") as f:
        f.write("\n".join(to_write))

    # Need to write stats on duplication.

    print("Done.")

